## v0.2 的核心目标
1. **文本流式**：用户发送后，前端能很快看到 assistant 的逐字/逐句输出（delta）。
2. **语音流式**：TTS 音频“边生成边播”，明显降低首包等待（T-first-audio）。
3. **强打断**：interrupt 体感 < 0.2s：停声、停嘴、停文本流。
4. **可观测**：每个 turn 有 trace/指标：首字延迟、首包音频延迟、总耗时、打断耗时。
5. **稳定性修复**：你记录的几个 bug 顺手修（至少把会阻碍 streaming 的修掉）。
---

# v0.2 工作拆解（按模块/优先级）
下面是“必须做（P0）/建议做（P1）/可选（P2）”分级清单。你按 P0 做完就能交付 v0.2。

## P0-1 协议层升级：明确“流式 + 可取消 + 可追踪”
把协议收敛成这几类事件（你后续扩展不会推倒重来）：

### 输入类
- `user_text { text }`
- `interrupt {}`（沿用）

### 文本流式类
- `assistant_delta { turn_id, text_delta }`
- `assistant_final { turn_id, text }`（最终版，便于校验/落盘）

### 音频流式类
- `audio_begin { turn_id, mime, sample_rate?, channels?, format? }`
- `audio_chunk { turn_id, seq, payload }`
- `audio_end { turn_id }`
- `audio_cancel { turn_id }` ✅（你前面提到的改动 A，v0.2 必做）

### 状态与指标类
- `state_update { turn_id, state }`（idle/thinking/speaking…）
- `metrics { turn_id, t_first_delta_ms, t_first_audio_ms, t_total_ms, t_interrupt_ms }`
**验收**：前端能完整处理上述消息；turn_id 不匹配的一律丢弃。
---

## P0-2 后端：LLM 流式生成（先解决你说的 local.py/hf_local.py 问题）
你提到的 “LLM流的问题 a：先解决 local.py 文本生成的问题”——这里就是 v0.2 的关键。

### 需要做的事
1. 在 `hf_local.py` 增加一个 **stream 接口**，例如：
    - `async def generate_stream(prompt) -> AsyncIterator[str]` 逐步 yield 新增 token/片段
2. 在 `ws.py` 的 turn workflow 中：
    - 收到 `user_text` 后立即 `state_update thinking`
    - 开始 `assistant_delta` 流式下发（边产边发）
    - 最终发 `assistant_final`
3. **取消机制**：
    - interrupt 时：cancel 当前 turn task；并保证 llm streaming 能“尽快停”（必要时用 `asyncio.to_thread` 包装阻塞调用）
    - interrupt 还要发 `audio_cancel`（P0-1 已覆盖）

### 实现建议（兼容你现有结构）
- **transformers 本地模型**的流式通常用 `TextIteratorStreamer` 或类似机制。
- 若你的生成是阻塞的（大概率是），用你记录的改动 B：
    - 把阻塞生成放进 `asyncio.to_thread(...)` 或单独线程
    - streaming 则用线程把 token 产出写入队列，ws 协程从队列取并发 `assistant_delta`
**验收**：
- 发送一句话后，前端 <1s 内能看到开始输出（哪怕一个字符）。
- interrupt 后文本不再继续增长（不会“幽灵 delta”）。
---

## P0-3 后端：TTS 音频真正流式（边产边发）
你 v0.1 里虽然有 chunk，但前端多半是 “等 end 再播”。v0.2 要做到“能边播”。

### 需要做的事
1. TTS 输出改成“可 chunk”且顺序稳定（加 `seq`）：
    - 每个 chunk 都带 `turn_id + seq`
2. interrupt 时：
    - 立即停止 TTS 产出（取消任务）
    - 发 `audio_cancel`（并且后续不再发同 turn 的 chunk）

### 关于你提到的 base64 CPU 问题（必须处理）
你记录的点很关键：`atob + for` 对长音频 CPU 压力大。
v0.2 有两条路线，建议按顺序做：
**路线 1（P0，最小改动）：保留 base64，但换更快的解码方式**
- Electron 场景如果允许用 Node Buffer（看你是否启用 nodeIntegration/preload），优先：
    - `Uint8Array.from(Buffer.from(b64, "base64"))`（通常比 atob+for 快）
- 若不方便用 Buffer，考虑引入轻量 base64 解码库（JS 实现更快、避免 charCodeAt 循环）
**路线 2（P1，性能更优）：改成 WebSocket 二进制帧**
- 直接发送 `bytes`，彻底避免 base64 33% 膨胀与解码 CPU
- 协议可以是：一个二进制包里包含 header+audio（例如 4 字节 header_len + header_json + raw_audio）
- 前端直接拿 `ArrayBuffer` → `Uint8Array`
**验收**：
- 连续播 20-30 秒音频，前端 CPU 不明显飙升，UI 不掉帧。
- 音频不乱序、不丢 chunk（seq 对不上就丢弃并记 log）。
---

## P0-4 前端：音频“边收边播”（核心体验升级）
这是 v0.2 的“展示点”。

### 你需要把前端播放从
- “收集 chunks → 拼接 → end 后播放”
    改为：
- “收到 chunk → 入队 → 立刻播放（或极短缓冲后播放）”

### 推荐实现路径（v0.2 最稳）
**优先推荐：PCM 流式播放（工程复杂度最低、效果最好）**
- 后端 TTS 输出 raw PCM16（比如 24kHz mono），`audio_begin` 里声明 `format=pcm_s16le, sample_rate=24000`
- 前端用 WebAudio：
    - 把 PCM16 chunk 转 Float32
    - 维护一个播放队列，按时间戳 schedule（或者用 AudioWorklet 做 ring buffer）
- lipsync 继续用 analyser 获取能量即可
**如果你现在 TTS 只能吐 mp3/wav**
- mp3 逐 chunk decode 并不友好（decodeAudioData 通常需要完整数据）
- wav 也不适合严格流式（每段有 header）
- 所以 v0.2 建议你就把 TTS 输出切到 PCM（哪怕只是内部传输 PCM，最终落盘再转封装）
**验收**：
- 输入后 <1s 内开始出声（目标是明显比 v0.1 快）。
- 能持续播放，不断裂、不爆音。
- interrupt 立即停声，队列清空。
---

## P0-5 前端：文本流式渲染 & 状态联动
1. 收到 `assistant_delta`：更新最后一条 assistant message 的 text（或 append）
2. 收到 `assistant_final`：校准最终文本
3. `state_update`：驱动 Live2D 表情（idle/thinking/speaking）
4. interrupt：停止音频 + 停嘴 + 停止文本更新（丢弃旧 turn）
**验收**：
- 文本在输出中不断增长；final 到来后不抖动。
- 被打断的 turn 不会再继续增长。
---

# 你记录的 bug / 技术债：v0.2 怎么处理最合适
你列的“需要修改的 bug”，我建议按下面方式纳入 v0.2（不拖慢主线，但保证不踩坑）。

## Bug-1 配置泄露/分散：WebSocket URL 等不应散落在组件里（P1）
你说的“容易泄露”更准确叫：**配置不可控/不可切环境**（dev/staging/prod）。
v0.2 建议做：
- 前端：统一 `src/config.ts` 或 `.env` + `VITE_WS_URL`
- Electron：通过 preload 注入运行时配置（更安全）
- 代码里禁止写死 ws://127.0.0.1:8000
**验收**：改 ws 地址只改一个地方。
> 你说“日志 list 暂时先不管”OK，但建议给 list 加上最大长度（比如 500 条），避免长时间跑内存涨。

## Bug-2 base64 解码吃 CPU（P0/P1）
P0：替换 atob+for 为更快解码方式
P1：升级二进制帧

## Bug-3 LLM 流问题（P0）
这就是 P0-2：`hf_local.py` 做 streaming + `ws.py` 做流式发送

## 改动 A audio_cancel（P0）
必须做；这是 streaming + interrupt 的“兜底保险”。

## 改动 B asyncio.to_thread（P0）
只要你的 LLM/TTS 任意一个是阻塞型，就必须做，否则 interrupt 体验一定不稳。

## 改动 C pdf.js worker 打包路径（P1）
v0.2 可以顺手做（避免你后面打包演示翻车），但不影响 streaming 主线。

# v0.2 建议的“里程碑交付”拆分（每一步都可验收）

### Milestone 1：文本流跑通
- 后端能发 `assistant_delta/final`
- 前端能实时更新文本
- interrupt 停止文本流

### Milestone 2：音频流跑通（先 base64）
- 后端发 `audio_begin/chunk/end` + seq
- 前端队列播放（先能边播）
- interrupt：audio_cancel 生效

### Milestone 3：性能与稳定性
- base64 解码优化 or 二进制帧
- 指标 metrics 上报与日志
- reconnect/close reason 可观测
---

# 我建议你下一步“先做哪三件事”（最小路径）
1. **把 LLM streaming 做出来**（hf_local.py + ws.py 的 assistant_delta/final）
2. **把音频从“end 后播”改成“边收边播”**（优先 PCM）
3. **audio_cancel + to_thread 确保打断可靠**（否则 streaming 会把 bug 放大）
