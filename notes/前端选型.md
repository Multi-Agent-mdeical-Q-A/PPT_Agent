# 模块一：前端 (Frontend)

## 1) 候选架构对比：Electron vs 纯 Web vs Tauri（以及为什么选 Electron）

### Electron（你当前选型）
**优点**
- **实时多媒体能力成熟**：Chromium + Node 生态，WebAudio/WebRTC/MediaStream/AudioWorklet 的兼容性与调试体验更成熟，做“实时对话（录音+播放+打断）”成本最低。
- **跨平台一致性强**：研究原型最怕环境差异；Electron 在 Win/macOS/Linux 体验相对一致。
- **本地资源访问方便**：PPT/PDF/图片序列/缓存、日志落盘、模型文件（若未来本地推理）都更顺。
- **UI/渲染灵活**：你后续做“PPT 画布 + 叠加层（字幕/高亮/指针）+ Live2D Canvas”这种组合，Electron 的 Web 技术栈天然适配。
**缺点**
- 体积大、内存占用高（但对研究原型可接受）。
- 进程模型复杂（主进程/渲染进程），需要做安全隔离（preload + contextBridge）。

### 纯 Web（浏览器网页）
**优点**
- 部署最轻、传播最方便（发一个链接就能跑）。
- 更新迭代快，天然在线。
**缺点（与你的“实时对话数字人 + PPT”冲突的点）**
- **本地文件与系统能力受限**：本地 PPT/PDF 读取、缓存、日志、设备权限在不同浏览器差异较大。
- **音频链路更难控**：浏览器权限、自动播放策略、后台标签页降频等，会影响“低延迟可打断”的体验一致性。
- 需要处理更多“用户环境不一致”的问题，不利于研究 Demo 稳定复现。

### Tauri（Rust + Webview）
**优点**
- 安装包更小、资源占用更低。
- Rust 后端更安全、性能好。
**缺点（对你现在阶段）**
- Webview 的媒体能力与调试体验通常不如 Chromium 稳（尤其在音频实时链路上更容易踩坑）。
- 生态/社区在“音频流、复杂渲染叠加、跨平台一致性”方面的资料密度不如 Electron。
- 你要把精力放在“AI 生成内容与对齐”，前端不应成为不确定性最大的一环。
✅ **因此：Electron 是“研究原型 + 多媒体实时交互”的最稳妥选型**：牺牲一些体积/内存，换来开发效率、稳定性、跨平台一致性和调试便利。
---

## 2) 版本演进路线（Roadmap）：v0.1 (MVP) → v1.0 (完整版)

### v0.1（MVP：先把“实时对话 + PPT 同屏 + Live2D 动嘴”跑通）
**目标**：可演示、可交互、可打断
- PPT 渲染：支持导入 PDF/图片序列并翻页
- 对话：按钮式录音（按住说/点击说），后端返回 TTS 音频并播放
- Live2D：显示 2D 角色；音频能量驱动嘴巴开合（不追求精细 viseme）
- WebSocket：最基础的消息协议（start/stop/audio_chunk/tts_chunk/interrupt）
- 打断：用户开始说话时立即停播、嘴型归零、通知后端 interrupt

### v0.2（可用性增强：更像“助教”）
- 字幕：显示 ASR partial / final 与助手流式文本
- 角色状态机：idle / listening / thinking / speaking 四态切换
- 会话管理：支持新对话、重试、清空上下文
- 音频体验：回声/啸叫的基础处理（至少做播放时降低麦克风增益、或 push-to-talk）

### v0.3（面向实验：可记录、可复现）
- 日志与回放：记录时间轴（用户语音段、ASR、LLM token、TTS 音频、翻页事件）
- UI 实验开关：比如“是否显示字幕”“是否自动翻页”等
- 错误容错：断线重连、后端超时、音频缓冲不足提示

### v0.5（引入“课件理解”的最小接口，但前端保持解耦）
- 右侧面板：显示“当前页讲解草稿/要点”（先当纯文本展示）
- “页上下文”协议：前端把当前页 ID/文本发送给后端，后端返回讲解内容（仍不做 ROI）

### v1.0（完整版前端：成为可扩展的“课件对话播放器”）
- 多层叠加：PPT 层 + ROI 高亮层 + 指针/焦点层 + Live2D 层 + 字幕/对话层
- 时间轴/可视化：支持定位到讲解的某一段（便于实验和演示）
- 多种输入：键盘快捷键、语音唤醒（可选）、手动选择“讲这个区域”
- 统一插件式渲染接口：Live2D 可替换为 3D/神经渲染头像（见扩展性部分）
---

## 3) 详细选型与落地：库、工程结构、以及技术栈组合逻辑

### 核心技术栈
- **Electron**：桌面容器（主进程负责窗口/系统能力；渲染进程负责 UI）
- **Vue 3**：UI 框架（组件化管理 PPT、Avatar、字幕、控制台）
- **WebSocket**：实时通信（v0 最快落地；后续可换 WebRTC）

### 状态管理与工程建议（你示例里提到 Pinia）
- **Pinia**：管理“会话状态机 + UI 状态 + 播放/录音状态”
    - 关键状态：`mode = idle/listening/thinking/speaking`、`currentSlide`、`wsConnected`、`audioQueue`、`interruptFlag`
- 路由：如果前端页面不多，Vue Router 可选；原型阶段可以不用。

### PPT/课件渲染层（建议从 PDF/图片序列开始）
- PDF：`pdf.js`（渲染到 canvas，翻页稳定）
- 图片序列：直接 `<img>` 或 canvas 绘制，性能更稳
- 坐标体系：无论 PDF 还是图片，都统一成“页面宽高 + 缩放比例”，为将来叠加层留接口

### Live2D 渲染承载层（Electron 里常见做法）
- **PixiJS**：作为 WebGL 渲染引擎（适合承载 Live2D 画布）
    - 逻辑：Pixi 渲染 Live2D → 作为独立 canvas 层叠在 PPT 上方/旁边
- 口型同步（v0 推荐）：WebAudio `AnalyserNode` 算能量 → 驱动 Live2D `MouthOpenY` 参数
    - 这能保证“实时 + 同步 + 可打断”最稳

### 通信协议（v0 就该定的“最小但可扩展”消息结构）
- 上行：`audio_chunk`（若你做语音上行）、`ui_event`（翻页/指向）、`interrupt`
- 下行：`asr_partial/asr_final`、`assistant_text_delta`、`tts_audio_chunk`、`state_update`
- 关键点：**中断语义**必须是“硬中断”，前端收到就立刻停播放+停嘴型

### 进程与安全建议（Electron 必做的底线）
- 主进程：只做系统能力（文件打开、窗口管理、权限）
- 渲染进程：UI + 音频 + Live2D
- preload：通过 `contextBridge` 暴露有限 API（避免直接打开 Node 权限到渲染层）
---

## 4) 架构扩展性：未来如何从 Live2D 升级到更高端的渲染方案？
你现在先用 Live2D 没问题，但要从一开始就把前端设计成**“Avatar Renderer 可插拔”**，这样以后升级不会重写一遍 UI。

### 抽象一个“Avatar Engine”接口（关键）
前端只依赖接口，不依赖实现：
- `init(container)`
- `setState(idle/listening/thinking/speaking)`
- `driveMouth(value | visemeTimeline)`
- `driveEmotion(valence/arousal | preset)`
- `stop()`（用于 interrupt）
- `destroy()`

### 升级路径建议（逐级替换，不动上层 UI）
- **Live2D（v0）**：能量驱动嘴型
- **Live2D（v0.5）**：改为 viseme 时间轴驱动（更准但仍轻量）
- **轻量 3D（v1.x）**：Three.js + VRM，输入变为 `blendshape`（接口保持一致）
- **高端实时驱动（v2）**：Audio2Face 等输出 ARKit blendshape，前端渲染层换 3D 或更高阶头部渲染
- **神经渲染（研究上限）**：将 AvatarLayer 替换为“视频纹理/流式帧”渲染，但仍复用同一套 `interrupt / state / timeline` 机制
> 这套扩展的核心思路是：**把“驱动信号”标准化**（mouthOpen / viseme / blendshape），把“渲染实现”当可替换插件。
