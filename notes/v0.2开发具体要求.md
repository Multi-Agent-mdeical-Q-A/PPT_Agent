# v0.2 开发看板（Streaming 数据通路）

## v0.2 里程碑划分
- **M1（P0）文本流**：后端 `assistant_delta`，前端实时渲染，不重复、不乱 turn
- **M2（P0）音频流体验**：音频“边收边播”，不再等 `audio_end` 才播放
- **M3（P0）强打断**：interrupt 立刻停声 + 后端补 `audio_cancel`，且阻塞调用可被“抢断到体感”
- **M4（P1）性能与工程化**：base64 解码优化/二进制帧、指标/日志、配置集中
---

## P0（必须做）Backlog

### BE-01（M1）HFLocalLLM 支持文本流式输出
**文件**：`services/llm/hf_local.py`  
**内容**
- 新增 `async def generate_stream(...) -> AsyncIterator[str]`：逐步 yield delta（token/片段）
- 保留现有 `generate()`（v0.1 兼容），但 v0.2 workflow 用 stream
**实现建议**
- transformers 本地流式可用 `TextIteratorStreamer` + 线程把 token 写入队列；ws 协程从队列读并发 `assistant_delta`
**验收**
- 单轮输入后 < 1s 能收到第一条 `assistant_delta`
- 流式结束后能得到完整 final 文本
**依赖**
- 你本地 transformers/torch 环境已 OK（你之前 sentencepiece 已处理）
---

### BE-02（M1）ws.py：从 assistant_reply 改为 assistant_delta + assistant_final
**文件**：`routers/ws.py`  
**现状**：你现在发送的是 `assistant_reply`（一次性全文），前端虽然写了 `assistant_delta` 分支，但后端没发。  
**内容**
- `run_turn_workflow()` 中：
    - `state_update: thinking`
    - 循环发送 `assistant_delta {turn_id, delta}`
    - 最后发送 `assistant_final {turn_id, text}`（或沿用 assistant_reply 但要避免前端重复消息）
**验收**
- 前端文本显示逐步增长
- 不出现“assistant 回复重复两条”（这点需要配合 FE-02 调整前端 handler）
---

### FE-01（M1）wsHandlers：修复“final 重复消息”，支持 assistant_final
**文件**：`src/stores/agent/wsHandlers.ts`  
**现状**：
- `assistant_delta` 已实现“追加到最后一条 assistant”
- `assistant_reply` 会 `push` 新 assistant，导致如果你既发 delta 又发 reply，会重复一条
**内容**
- 增加 `case "assistant_final"`：
    - 若最后一条是同 turn 的 assistant：`last.text = finalText`
    - 否则：新建一条（兜底）
- 同时把 `assistant_reply` 的逻辑改为“final 合并”（兼容旧消息类型）
**验收**
- 流式期间只有 1 条 assistant 在增长
- final 到来后不会多出一条新 assistant
---

### FE-02（M1）index.ts：修复 thisStore 顺序 bug + turnId 乐观更新
**文件**：`src/stores/agent/index.ts`  
**现状问题**
- `handleServerMessage()` 里 `wsCtx` getter 用到了 `thisStore`，但 `const thisStore = this` 在后面（这是你之前提到过的点，当前文件仍存在）
- `sendUserText()` 把 user message 的 `turnId` 写成 `this.turnId`，而后端收到 user_text 会 turn+1，导致 UI turn 对不上
**内容**
1. `handleServerMessage()`：把 `const thisStore = this;` 提到 `wsCtx` 之前
2. `sendUserText()`：做“乐观 +1”
    - `const nextTurn = this.turnId + 1; this.turnId = nextTurn;`
    - user message 的 `turnId: nextTurn`
**验收**
- TS 不再出现 used-before-declare 风险
- user/assistant 同一轮 turnId 对齐
---

### BE-03（M3）interrupt：后端补 audio_cancel（你记录的改动 A）
**文件**：`routers/ws.py`  
**现状**：interrupt 只 `state_update idle`，没发 `audio_cancel`  
**内容**
- 在 `mtype == "interrupt"` 分支：
    - `workflow_task.cancel()`
    - 发送 `{"type":"audio_cancel","turn_id": state.turn_id}`（在 idle 前后都可，但建议在 idle 前）
- 在 `run_turn_workflow()` 的 `CancelledError` 捕获里，也补发 `audio_cancel`（避免 race）
**验收**
- interrupt 后，前端即使还有迟到的 audio_chunk，也会被明确 cancel 掉
- debugLog 能看到 audio_cancel
---

### FE-03（M3）前端音频：从“buffer后播放”升级为“边收边播”
**文件**：`src/stores/agent/audio.ts` + `wsHandlers.ts`  
**现状**：`audio_end` 时 `playBufferedAudio()` 合并 chunks 后播放（对长音频 CPU/内存很不友好，也不是流式体验）
**内容（推荐方案：MediaSource + audio/mpeg，兼容 EdgeTTS）**
1. `audio.ts` 新增一套 streaming API（不破坏原有 buffered API）：
    - `startStream(mime: string)`
    - `appendStreamChunk(u8: Uint8Array)`
    - `endStream()`
    - `cancelStream(reason)`
    - 内部用 `MediaSource` + `SourceBuffer`（mime=audio/mpeg）
2. `wsHandlers.ts`：
    - `audio_begin`：调用 `startStream(mime)`（若不支持 MSE 再 fallback 到老的 buffer 方式）
    - `audio_chunk`：append 到 stream（fallback 模式仍 push 到 audioChunks）
    - `audio_end`：`endStream()`（fallback 才 playBufferedAudio）
**验收**
- 音频在 `audio_end` 之前就能开始播放（明显更快）
- 长音频不卡 UI、不需要一次性合并大数组
- `audio_cancel` 能立刻停声并清理队列
---

### FE-04（M3）TTS base64 解码 CPU 优化（你记录的 bug 1）
**文件**：`src/stores/agent/utils.ts`（你这次没上传，但 wsHandlers 在用 `base64ToU8`）  
**内容**
- 优先加一个快速路径：
    - 若运行环境可用 `Buffer`：`Uint8Array.from(Buffer.from(b64, "base64"))`
    - 否则 fallback 到 `atob`，但避免 “for + charCodeAt” 的最慢写法（用更快实现或查表解码）
- 同时由于 v0.2 改为流播，单次 chunk 更小，CPU压力会明显下降；但解码仍值得优化
**验收**
- 30s 音频播放期间 CPU 占用不明显飙升
- debugLog 无 decode error
---

## P1（建议做）Backlog（做完更像“工程化 v0.2”）

### BE-04（M2+）“伪真·语音流”：按句切分文本 → 多段 TTS 连续输出
**文件**：`routers/ws.py`  
**动机**：EdgeTTS 需要完整 text 才能生成，但我们想让“边出字边出声”  
**内容**
- LLM `assistant_delta` 在后台累计 buffer
- 检测到句号/问号/感叹号或长度阈值 → 触发一次 TTS（只对这一句）
- 统一一个 `audio_begin`，全程 seq 递增，把各句的音频 chunk 连续 append 给前端
- 末尾发 `audio_end`
**验收**
- 你能看到“文字还在继续生成，但音频已经开始播第一句”
---

### FE-05（工程化）连接状态机：加入 connecting，避免误触重连
**文件**：`src/stores/agent/types.ts`、`index.ts`  
**现状**：ConnectionStatus 只有 disconnected/connected/closed；connect 后立刻用 `isOpen()` 判断会误显示 disconnected  
**内容**
- `ConnectionStatus` 加 `"connecting"`
- `connect()/reconnect()`：如果 ws.isConnecting() 就 set connecting；connecting 时禁用 reconnect
**验收**
- 不会出现“一直 connecting + 手动点 reconnect 把连接打断”的循环
---

### FE-06（工程化）debugLog 改成环形缓冲（你说暂时用 list 也可以）
**文件**：`index.ts`  
**内容**
- `addDebug()` 里对数组长度做上限（例如 300/500），超出丢尾部
**验收**
- 长时间运行不会因为日志无限增长导致内存上涨
---

### FE-07（工程化）配置集中：WS URL 等挪到 config
**文件**：新增 `src/config.ts`（或 `.env` 管理）  
**内容**
- 统一读取 `VITE_WS_URL`
- 组件/store 不再写死 ws 地址（降低泄露 & 易切环境）
**验收**
- 切换后端只改 1 处
---

### FE-08（打包稳定）pdf.js worker 路径修复（你记录的改动 C）
**文件**：`SlideViewer.vue`（你这次没上传）  
**内容**
- workerSrc 不用 `"/pdf.worker.min.mjs"` 这种绝对路径
- 按你构建工具（Vite）用 `new URL(..., import.meta.url)` 或静态拷贝方式固定路径
**验收**
- Electron 打包后 PDF 翻页正常，不报 worker load error
---

## P2（可选）性能最优：WebSocket 二进制帧替代 base64
**BE-05 + FE-09**
- 后端直接 send bytes（ws.send_bytes）或发送 binary frame
- 前端直接拿 `ArrayBuffer` append，无需 base64 decode
- 这是性能最优，但要同时改协议与前端 ws service
---

# 建议你按这个顺序做（最短路径能跑通 v0.2）
1. **BE-01 + BE-02 + FE-01**：文本流闭环（先把 delta 跑起来）
2. **BE-03 + FE-03**：音频流播 + audio_cancel（打断变可靠）
3. **FE-02**：thisStore/turnId 这些基础 bug 修掉（否则流式更容易出怪问题）
4. **FE-04（解码优化）/ BE-04（句子级 TTS）**：体验升级
