import os
from typing import List, Dict, Generator
from tqdm import tqdm

class BatchDataLoader:
    def __init__(self, input_file_path: str, batch_size: int = 8, ndocs: int = 10):
        """
        input_file_path: å¯¹åº” test_popqa.txt
        batch_size: æ‰¹å¤„ç†å¤§å°
        ndocs: æ¯ä¸ªé—®é¢˜å¯¹åº”çš„æ£€ç´¢æ–‡æ¡£æ•° (CRAG é»˜è®¤ä¸º 10)
        """
        self.batch_size = batch_size
        self.ndocs = ndocs
        self.data = self._load_data(input_file_path)
        print(f"ðŸ“¦ [DataLoader] Successfully loaded {len(self.data)} questions from {input_file_path}")

    def _load_data(self, path):
        if not os.path.exists(path):
            raise FileNotFoundError(f"{path} not found")

        samples = []
        
        print(f"â³ [DataLoader] Parsing file...")
        with open(path, 'r', encoding='utf-8') as f:
            lines = f.readlines()
            
        # è®¡ç®—æ€»é—®é¢˜æ•°
        total_questions = len(lines) // self.ndocs
        
        for i in tqdm(range(total_questions), desc="Loading Data"):
            # å–å‡ºå±žäºŽå½“å‰é—®é¢˜çš„ chunk (ndocsè¡Œ)
            chunk = lines[i*self.ndocs : (i+1)*self.ndocs]
            
            # 1. æå– Question (å– Chunk çš„ç¬¬ä¸€è¡Œå³å¯)
            # æ ¼å¼: "Who is ... [SEP] Doc..."
            first_line = chunk[0].strip()
            parts = first_line.split(" [SEP] ") # æ³¨æ„ç©ºæ ¼
            
            if len(parts) >= 1:
                question = parts[0]
            else:
                question = "" # å¼‚å¸¸æ•°æ®å…œåº•

            # 2. æå– 10 ä¸ª Pure Docs (ä¸å« Queryï¼Œä¸å« [SEP])
            raw_docs = []
            for line in chunk:
                # åŽ»æŽ‰è¡Œæœ«å¯èƒ½çš„ label (æ¯”å¦‚ "\t0")
                line_content = line.strip().split("\t")[0]
                
                # ã€å…³é”®ä¿®æ­£ã€‘æ‹†åˆ†å‡º Doc éƒ¨åˆ†
                # å‡è®¾æ ¼å¼ä¸¥æ ¼ä¸º "Query [SEP] Doc"
                seg_parts = line_content.split(" [SEP] ")
                if len(seg_parts) >= 2:
                    # å– [SEP] åŽé¢çš„éƒ¨åˆ†ä½œä¸ºæ–‡æ¡£
                    # æœ‰æ—¶å€™æ–‡æ¡£é‡Œä¹Ÿæœ‰ [SEP]ï¼Œæ‰€ä»¥è¦å– [1:] å¹¶ join æ¯”è¾ƒç¨³å¦¥ï¼Œæˆ–è€…åªå– [1]
                    doc_text = " ".join(seg_parts[1:]) 
                else:
                    # å¦‚æžœæ²¡æœ‰ [SEP]ï¼Œå¯èƒ½è¿™è¡Œå°±æ˜¯çº¯æ–‡æ¡£ï¼Œæˆ–è€…æ ¼å¼åäº†
                    doc_text = line_content
                
                raw_docs.append(doc_text)

            samples.append({
                "id": i,               # int, ç”¨äºŽ RefinerTool ç´¢å¼•
                "query": question,     # str
                "raw_docs": raw_docs,  # List[str], çº¯æ–‡æ¡£å†…å®¹
                "golds": []            # é¢„ç•™ç»™æ ‡å‡†ç­”æ¡ˆ (å¦‚æžœæœ‰çš„è¯)
            })
            
        return samples

    def get_batches(self) -> Generator[Dict[str, List], None, None]:
        """
        ç”Ÿæˆå™¨ï¼Œæ¯æ¬¡ yield ä¸€ä¸ª batch
        """
        total = len(self.data)
        # ä½¿ç”¨ yield èŠ‚çœå†…å­˜
        for i in range(0, total, self.batch_size):
            batch_samples = self.data[i : i + self.batch_size]
            
            # æž„é€  Batch å­—å…¸ (Column-oriented format)
            # è¿™ç§æ ¼å¼æœ€é€‚åˆ Agent æ‰¹é‡å¤„ç†
            batch = {
                "ids": [s["id"] for s in batch_samples],          # List[int]
                "queries": [s["query"] for s in batch_samples],    # List[str]
                "raw_docs": [s["raw_docs"] for s in batch_samples] # List[List[str]] -> [Batch, 10]
            }
            yield batch