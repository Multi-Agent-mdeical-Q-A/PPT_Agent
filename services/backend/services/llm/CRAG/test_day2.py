import sys
import os

# 1. ç¡®ä¿ Python èƒ½æ‰¾åˆ°ä½ çš„é¡¹ç›®åŒ… (my_agentic_rag)
# å°†å½“å‰è„šæœ¬æ‰€åœ¨çš„ç›®å½•æ·»åŠ åˆ°ç³»ç»Ÿè·¯å¾„ä¸­
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from .config.config_loader import settings
from .core_layer.evaluator_tool import EvaluatorTool
from .core_layer.refiner_tool import RefinerTool
from .data_layer.loader import BatchDataLoader

def test_components():
    print("ğŸš€ Starting Component Integration Test...\n")

    # ==========================================
    # 1. Test DataLoader (æ•°æ®çš„æºå¤´)
    # ==========================================
    print("=== [1] Test DataLoader ===")
    print(f"Loading data from: {settings.paths['input_file']}")
    
    loader = BatchDataLoader(
        input_file_path=settings.paths['input_file'],
        batch_size=2, # æµ‹è¯•åªå– 2 æ¡æ•°æ®
        ndocs=10
    )
    
    # è·å–ç¬¬ä¸€ä¸ª Batch
    batch_gen = loader.get_batches()
    try:
        batch = next(batch_gen)
    except StopIteration:
        print("âŒ Error: Data file is empty or path is wrong.")
        return

    print(f"âœ… Batch Keys: {list(batch.keys())}")
    print(f"âœ… Batch Queries: {batch['queries']}")
    print(f"âœ… IDs: {batch['ids']}")
    
    # æ£€æŸ¥ Raw Docs å½¢çŠ¶: åº”è¯¥æ˜¯ [Batch_Size, 10]
    raw_docs_shape = (len(batch['raw_docs']), len(batch['raw_docs'][0]))
    print(f"âœ… Raw Docs Shape: {raw_docs_shape} (Expected: (2, 10))")
    
    
    # ==========================================
    # 2. Test Evaluator (è£åˆ¤)
    # ==========================================
    print("\n=== [2] Test Evaluator ===")
    evaluator = EvaluatorTool(settings.models['evaluator_path'])
    
    # åœºæ™¯æ¨¡æ‹Ÿï¼šç»™ Batch ä¸­ç¬¬ 0 ä¸ªé—®é¢˜çš„ 10 ç¯‡æ–‡æ¡£æ‰“åˆ†
    q0 = batch['queries'][0]      # "Who is..."
    docs0 = batch['raw_docs'][0]  # List[str] (10ç¯‡æ–‡æ¡£)
    id0 = batch['ids'][0]         # int ID
    
    print(f"Query: {q0}")
    
    # ã€å…³é”®ã€‘æ„é€  Evaluator è¾“å…¥
    # run_pair éœ€è¦ List[Query] å’Œ List[Doc] é•¿åº¦å¯¹é½
    # æ‰€ä»¥æˆ‘ä»¬éœ€è¦æŠŠ q0 é‡å¤ 10 æ¬¡ï¼Œå˜æˆ ["Who...", "Who...", ...]
    queries_repeated = [q0] * len(docs0)
    
    # è¿™é‡Œçš„ ids å‚æ•°æ˜¯å¯é€‰çš„ï¼Œä½†ä¸ºäº†æµ‹è¯• Trace æœ€å¥½ä¼ è¿›å»ï¼ˆè™½ç„¶è¿™é‡Œæˆ‘ä»¬åªä¼ ä¸ª None å ä½ä¹Ÿå¯ä»¥ï¼‰
    # å¦‚æœè¦ä¼  idsï¼Œä¹Ÿå¾—æ˜¯ Listï¼Œä¸”é•¿åº¦å¯¹åº”
    ids_repeated = [str(id0)] * len(docs0) 

    scores = evaluator.run_pair(queries_repeated, docs0, ids=ids_repeated)
    
    print(f"âœ… Scores (10 docs): {scores}")
    print(f"   -> Max Score: {max(scores)}")
    print(f"   -> Min Score: {min(scores)}")


    # ==========================================
    # 3. Test Refiner (çŸ¥è¯†åº“/æŸ¥è¡¨)
    # ==========================================
    print("\n=== [3] Test Refiner (Mock Retriever) ===")
    refiner = RefinerTool(
        settings.paths['internal_ref'],
        settings.paths['external_ref'],
        settings.paths['combined_ref']
    )
    
    # åœºæ™¯æ¨¡æ‹Ÿï¼šå‡è®¾ Agent å†³å®šå»æŸ¥ 'internal' (Correct) çŸ¥è¯†åº“
    # Refiner æ¥æ”¶çš„æ˜¯ IDs (List[int])
    target_ids = batch['ids'] # [0, 1]
    
    refined_docs = refiner.run(target_ids, type='internal')
    
    print(f"âœ… Refined Docs Count: {len(refined_docs)}")
    print(f"âœ… Doc for ID {target_ids[0]} (Internal): {refined_docs[0][:50]}...")
    
    # å†æµ‹è¯•ä¸€ä¸‹æŸ¥ external
    incorrect_docs = refiner.run(target_ids, type='external')
    print(f"âœ… Doc for ID {target_ids[0]} (External): {incorrect_docs[0][:50]}...")

    print("\nğŸ‰ All components passed the test!")

if __name__ == "__main__":
    test_components()
