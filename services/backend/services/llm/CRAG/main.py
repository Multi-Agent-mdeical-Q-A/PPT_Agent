import os
from tqdm import tqdm

# 1. å¯¼å…¥é…ç½®
from .config.config_loader import settings

# 2. å¯¼å…¥ç»„ä»¶
from .core_layer.generator_tool import GeneratorTool
from .core_layer.evaluator_tool import EvaluatorTool
from .core_layer.refiner_tool import RefinerTool
from .data_layer.loader import BatchDataLoader
from .control_layer.crag_agent import CragAgent

def main():
    # --- 0. å¯åŠ¨æ—¥å¿— (ä¸å†éœ€è¦ argparse) ---
    print(f"ğŸš€ Starting Agentic CRAG...")
    print(f"   Task:   {settings.task_name}")
    print(f"   Method: {settings.params.get('method')}")
    print(f"   Device: {settings.params.get('device')}")

    # --- 1. åˆå§‹åŒ– Core Layer ---
    print("\n[1/4] Initializing Core Tools...")
    
    # Generator: æ˜¾å¼ä¼ é€’æ˜¾å­˜å‚æ•°
    generator = GeneratorTool(
        model_path=settings.models['generator_path'],
        max_model_len=settings.params.get('max_model_len', 2048),
        # è¯»å– yaml ä¸­çš„ gpu_memory_utilizationï¼Œå¦‚æœæ²¡æœ‰åˆ™é»˜è®¤ 0.7
        gpu_utilization=settings.params.get('gpu_memory_utilization', 0.7)
    )
    
    # Evaluator: ä¼ é€’ Device å‚æ•°
    evaluator = EvaluatorTool(
        model_path=settings.models['evaluator_path'],
        device=settings.params.get('device', 'cuda:0')
    )
    
    refiner = RefinerTool(
        internal_path=settings.paths['internal_ref'],
        external_path=settings.paths['external_ref'],
        combined_path=settings.paths['combined_ref']
    )
    
    tools = {
        "generator": generator,
        "evaluator": evaluator,
        "refiner": refiner
    }

    # --- 2. åˆå§‹åŒ– Control Layer ---
    print("\n[2/4] Initializing Agent...")
    agent = CragAgent(tools)

    # --- 3. åˆå§‹åŒ– Data Layer ---
    print("\n[3/4] Loading Data...")
    loader = BatchDataLoader(
        input_file_path=settings.paths['input_file'],
        batch_size=settings.params.get('batch_size', 8),
        ndocs=settings.params.get('ndocs', 10) # åŠ¨æ€è¯»å– ndocs
    )

    # --- 4. ä¸»å¾ªç¯ ---
    print(f"\n[4/4] Running Inference (Batch Size={loader.batch_size})...")
    
    all_predictions = []
    # é˜²æ­¢é™¤é›¶é”™è¯¯
    if loader.batch_size > 0:
        total_batches = (len(loader.data) + loader.batch_size - 1) // loader.batch_size
    else:
        total_batches = 0

    # åœ¨ main.py çš„å¾ªç¯é‡Œ
    for batch_data in tqdm(loader.get_batches(), total=total_batches, desc="Processing Batches"):
        try:
            batch_answers = agent.run_batch(batch_data)
            
            # ã€è°ƒè¯•ä»£ç ã€‘æ£€æŸ¥é•¿åº¦æ˜¯å¦å¯¹é½
            input_len = len(batch_data['ids'])
            output_len = len(batch_answers)
            
            if input_len != output_len:
                print(f"\nğŸš¨ Data Mismatch in batch {batch_data['ids'][0]}!")
                print(f"   Input: {input_len}, Output: {output_len}")
                # å¼ºè¡Œè¡¥é½ï¼Œé˜²æ­¢é”™ä½
                diff = input_len - output_len
                batch_answers.extend(["Error"] * diff)
            
            all_predictions.extend(batch_answers)
            
        except Exception as e:
            print(f"\nâŒ Error in batch {batch_data.get('ids', 'unknown')}: {e}")
            # é”™è¯¯å¡«å……
            if 'ids' in batch_data:
                all_predictions.extend(["Error"] * len(batch_data['ids']))
                
    # --- 5. ä¿å­˜ç»“æœ ---
    output_file = settings.paths['output_file']
    print(f"\nğŸ’¾ Saving {len(all_predictions)} predictions to {output_file}...")
    
    os.makedirs(os.path.dirname(output_file), exist_ok=True)
    
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write('\n'.join(all_predictions))
        
    print("âœ¨ Inference Complete!")

if __name__ == "__main__":
    main()
