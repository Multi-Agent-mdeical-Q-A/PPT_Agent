#!/usr/bin/env python3
"""
batch_ppt_to_marp.py (v2.0)
===========================
æ‰¹é‡å°† PPTX è¯¾ä»¶è½¬æ¢ä¸º Marp Markdown æ ¼å¼ï¼Œä¸“ä¸ºå¤šè½® AI å†…å®¹é‡æ„ä¼˜åŒ–ã€‚

æ ¸å¿ƒæ”¹è¿› (v2.0):
- ğŸ¯ ä¿ç•™åŸå§‹æ ‡é¢˜ï¼šæ— æ ‡é¢˜æ—¶æ™ºèƒ½å›é€€ï¼Œç»ä¸ç”¨é¡µç å ä½
- ğŸ“Š ä¸°å¯Œçš„ç»“æ„åŒ–å…ƒæ•°æ®ï¼šå±‚çº§å…³ç³»ã€å†…å®¹ç±»å‹ã€å¸ƒå±€ä¿¡æ¯
- ğŸ”— å¹»ç¯ç‰‡é—´å…³ç³»æ¨æ–­ï¼šç« èŠ‚æ£€æµ‹ã€å†…å®¹è¿ç»­æ€§æ ‡è®°
- ğŸ“ å¢å¼ºçš„æ–‡æœ¬æå–ï¼šä¿ç•™å±‚çº§ç¼©è¿›ã€è¯†åˆ«åˆ—è¡¨ vs æ®µè½
- ğŸ–¼ï¸ æ™ºèƒ½å›¾ç‰‡å¤„ç†ï¼šä½ç½®ä¿¡æ¯ã€å°ºå¯¸æ¯”ä¾‹ã€å¤šå›¾å¸ƒå±€å»ºè®®
- ğŸ·ï¸ AI å‹å¥½çš„æ ‡ç­¾ç³»ç»Ÿï¼šæ–¹ä¾¿ä¸‹æ¸¸å·¥å…·è§£æå’Œå¤„ç†
- ğŸ“ˆ å†…å®¹è´¨é‡æŒ‡æ ‡ï¼šæ–‡å­—å¯†åº¦ã€å›¾æ–‡æ¯”ä¾‹ç­‰

ä½¿ç”¨æ–¹æ³•ï¼š
    python batch_ppt_to_marp.py [--verbose] [--output-dir DIR]

ä¾èµ–ï¼š
    pip install python-pptx --break-system-packages
"""

import os
import sys
import re
import json
import hashlib
from pathlib import Path
from typing import Optional, Tuple, List, Dict, Any
from dataclasses import dataclass, field, asdict
from datetime import datetime
from enum import Enum

try:
    from pptx import Presentation
    from pptx.util import Inches, Pt, Emu
    from pptx.enum.shapes import MSO_SHAPE_TYPE
    from pptx.enum.text import PP_ALIGN
except ImportError:
    print("=" * 60)
    print("Error: python-pptx æœªå®‰è£…")
    print("è¯·è¿è¡Œä»¥ä¸‹å‘½ä»¤å®‰è£…:")
    print("  pip install python-pptx --break-system-packages")
    print("=" * 60)
    sys.exit(1)


# =============================================================================
# æ•°æ®ç»“æ„å®šä¹‰
# =============================================================================

class SlideType(Enum):
    """å¹»ç¯ç‰‡ç±»å‹åˆ†ç±»"""
    TITLE = "title"           # æ ‡é¢˜é¡µ/å°é¢
    SECTION = "section"       # ç« èŠ‚åˆ†éš”é¡µ
    CONTENT = "content"       # æ™®é€šå†…å®¹é¡µ
    IMAGE_ONLY = "image_only" # çº¯å›¾ç‰‡é¡µ
    TEXT_ONLY = "text_only"   # çº¯æ–‡å­—é¡µ
    MIXED = "mixed"           # å›¾æ–‡æ··æ’
    BLANK = "blank"           # ç©ºç™½é¡µ
    ENDING = "ending"         # ç»“æŸé¡µ


class ContentDensity(Enum):
    """å†…å®¹å¯†åº¦è¯„ä¼°"""
    SPARSE = "sparse"     # ç¨€ç–ï¼ˆé€‚åˆæ‰©å±•ï¼‰
    NORMAL = "normal"     # æ­£å¸¸
    DENSE = "dense"       # å¯†é›†ï¼ˆå¯èƒ½éœ€è¦æ‹†åˆ†ï¼‰


@dataclass
class ImageInfo:
    """å›¾ç‰‡ä¿¡æ¯"""
    filename: str
    original_name: str
    width_emu: int
    height_emu: int
    left_emu: int
    top_emu: int
    aspect_ratio: float
    position_hint: str  # "left", "right", "center", "full"
    size_hint: str      # "small", "medium", "large", "full"
    
    def to_marp_directive(self, asset_path: str) -> str:
        """ç”Ÿæˆ Marp å›¾ç‰‡æŒ‡ä»¤"""
        # æ ¹æ®ä½ç½®å’Œå¤§å°ç”Ÿæˆæœ€ä½³å¸ƒå±€
        if self.size_hint == "full":
            return f"![bg contain]({asset_path})"
        elif self.position_hint == "right":
            width_pct = "40%" if self.size_hint == "large" else "35%"
            return f"![bg right:{width_pct} fit]({asset_path})"
        elif self.position_hint == "left":
            width_pct = "40%" if self.size_hint == "large" else "35%"
            return f"![bg left:{width_pct} fit]({asset_path})"
        else:
            return f"![bg right:35% fit]({asset_path})"


@dataclass
class TextBlock:
    """æ–‡æœ¬å—ä¿¡æ¯"""
    text: str
    level: int              # ç¼©è¿›å±‚çº§ (0=é¡¶çº§)
    is_title: bool
    is_subtitle: bool
    is_bullet: bool
    font_size: Optional[float]  # å­—å·ï¼ˆç£…ï¼‰
    is_bold: bool
    shape_type: str         # "title", "body", "textbox", "other"


@dataclass
class SlideData:
    """å•å¼ å¹»ç¯ç‰‡çš„ç»“æ„åŒ–æ•°æ®"""
    index: int
    total: int
    
    # å†…å®¹
    title: Optional[str]
    subtitle: Optional[str]
    text_blocks: List[TextBlock]
    images: List[ImageInfo]
    speaker_notes: str
    
    # å…ƒæ•°æ®
    slide_type: SlideType
    content_density: ContentDensity
    has_animation: bool
    layout_name: str
    
    # AI è¾…åŠ©ä¿¡æ¯
    is_section_start: bool
    section_title: Optional[str]
    estimated_speak_time_sec: int
    key_terms: List[str]
    
    # å…³ç³»
    continues_from_previous: bool
    continues_to_next: bool


# =============================================================================
# å·¥å…·å‡½æ•°
# =============================================================================

def sanitize_filename(name: str) -> str:
    """æ¸…ç†æ–‡ä»¶å"""
    sanitized = re.sub(r'[<>:"/\\|?*]', '_', name)
    sanitized = re.sub(r'\s+', '_', sanitized)
    sanitized = re.sub(r'_+', '_', sanitized)
    return sanitized.strip('_')


def emu_to_inches(emu: int) -> float:
    """EMU è½¬è‹±å¯¸"""
    return emu / 914400


def estimate_speak_time(text_content: str, notes: str) -> int:
    """ä¼°ç®—æ¼”è®²æ—¶é—´ï¼ˆç§’ï¼‰"""
    # ä¸­æ–‡çº¦ 150 å­—/åˆ†é’Ÿï¼Œè‹±æ–‡çº¦ 130 è¯/åˆ†é’Ÿ
    total_chars = len(text_content) + len(notes)
    # ç²—ç•¥ä¼°ç®—ï¼šæ¯ä¸ªå­—ç¬¦çº¦ 0.4 ç§’
    return max(30, int(total_chars * 0.4))


def extract_key_terms(text: str) -> List[str]:
    """æå–å…³é”®æœ¯è¯­ï¼ˆç®€å•å®ç°ï¼‰"""
    # æå–å¼•å·å†…å®¹ã€å¤§å†™ç¼©å†™ã€ä¸“æœ‰åè¯ç­‰
    terms = []
    
    # å¼•å·å†…å®¹
    quoted = re.findall(r'[""ã€Œã€ã€ã€]([^""ã€Œã€ã€ã€]+)[""ã€Œã€ã€ã€]', text)
    terms.extend(quoted)
    
    # è‹±æ–‡ç¼©å†™ (2-5ä¸ªå¤§å†™å­—æ¯)
    abbrevs = re.findall(r'\b[A-Z]{2,5}\b', text)
    terms.extend(abbrevs)
    
    # å»é‡å¹¶é™åˆ¶æ•°é‡
    seen = set()
    unique_terms = []
    for t in terms:
        t_lower = t.lower()
        if t_lower not in seen and len(t) > 1:
            seen.add(t_lower)
            unique_terms.append(t)
    
    return unique_terms[:10]


def detect_slide_type(title: Optional[str], text_blocks: List[TextBlock], 
                      images: List[ImageInfo], layout_name: str) -> SlideType:
    """æ£€æµ‹å¹»ç¯ç‰‡ç±»å‹"""
    has_text = bool(text_blocks)
    has_images = bool(images)
    
    # æ£€æŸ¥å¸ƒå±€åç§°ä¸­çš„å…³é”®è¯
    layout_lower = layout_name.lower()
    if any(kw in layout_lower for kw in ['title', 'æ ‡é¢˜', 'å°é¢']):
        if 'section' in layout_lower or 'èŠ‚' in layout_lower:
            return SlideType.SECTION
        return SlideType.TITLE
    
    if any(kw in layout_lower for kw in ['blank', 'ç©ºç™½']):
        return SlideType.BLANK
    
    if any(kw in layout_lower for kw in ['end', 'ç»“æŸ', 'thank', 'è°¢è°¢']):
        return SlideType.ENDING
    
    # åŸºäºå†…å®¹åˆ¤æ–­
    if not has_text and not has_images:
        return SlideType.BLANK
    elif has_images and not has_text:
        return SlideType.IMAGE_ONLY
    elif has_text and not has_images:
        return SlideType.TEXT_ONLY
    else:
        return SlideType.MIXED


def assess_content_density(text_blocks: List[TextBlock], images: List[ImageInfo]) -> ContentDensity:
    """è¯„ä¼°å†…å®¹å¯†åº¦"""
    total_text_len = sum(len(tb.text) for tb in text_blocks)
    num_items = len(text_blocks) + len(images)
    
    if total_text_len < 50 and num_items <= 2:
        return ContentDensity.SPARSE
    elif total_text_len > 500 or num_items > 8:
        return ContentDensity.DENSE
    else:
        return ContentDensity.NORMAL


def is_continuation_title(title: str) -> bool:
    """æ£€æŸ¥æ˜¯å¦æ˜¯å»¶ç»­æ€§æ ‡é¢˜ï¼ˆå¦‚ "xxxï¼ˆç»­ï¼‰"ï¼‰"""
    if not title:
        return False
    patterns = [
        r'[\(ï¼ˆ][ç»­ç»§][\)ï¼‰]',
        r'cont[\'.]?d?',
        r'continued',
        r'part\s*\d+',
        r'[ï¼ˆ\(]\d+[ï¼‰\)]$',
    ]
    title_lower = title.lower()
    return any(re.search(p, title_lower) for p in patterns)


def detect_section_start(title: str, layout_name: str, prev_title: Optional[str]) -> Tuple[bool, Optional[str]]:
    """æ£€æµ‹æ˜¯å¦æ˜¯ç« èŠ‚å¼€å§‹"""
    if not title:
        return False, None
    
    layout_lower = layout_name.lower()
    
    # å¸ƒå±€åç§°åŒ…å« section
    if 'section' in layout_lower or 'èŠ‚' in layout_lower:
        return True, title
    
    # æ ‡é¢˜æ ¼å¼æ£€æµ‹ï¼šæ•°å­—å¼€å¤´ã€"ç¬¬Xç« /èŠ‚" ç­‰
    section_patterns = [
        r'^ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å\d]+[ç« èŠ‚è®²è¯¾]',
        r'^\d+[\.\ã€]\s*\S',
        r'^[IVX]+[\.\ã€]\s*\S',
        r'^(Chapter|Lecture|Week|Part)\s*\d+',
    ]
    
    for pattern in section_patterns:
        if re.match(pattern, title, re.IGNORECASE):
            return True, title
    
    return False, None


# =============================================================================
# æ ¸å¿ƒæå–å‡½æ•°
# =============================================================================

def get_image_position_hint(left_emu: int, top_emu: int, width_emu: int, 
                            slide_width: int, slide_height: int) -> str:
    """æ ¹æ®ä½ç½®åˆ¤æ–­å›¾ç‰‡åº”è¯¥æ”¾åœ¨å“ªé‡Œ"""
    center_x = left_emu + width_emu / 2
    slide_center = slide_width / 2
    
    # åˆ¤æ–­æ°´å¹³ä½ç½®
    if center_x < slide_center * 0.6:
        return "left"
    elif center_x > slide_center * 1.4:
        return "right"
    else:
        return "center"


def get_image_size_hint(width_emu: int, height_emu: int, 
                        slide_width: int, slide_height: int) -> str:
    """æ ¹æ®å°ºå¯¸åˆ¤æ–­å›¾ç‰‡å¤§å°çº§åˆ«"""
    area_ratio = (width_emu * height_emu) / (slide_width * slide_height)
    
    if area_ratio > 0.5:
        return "full"
    elif area_ratio > 0.25:
        return "large"
    elif area_ratio > 0.1:
        return "medium"
    else:
        return "small"


def extract_images_enhanced(slide, slide_num: int, output_dir: Path,
                            slide_width: int, slide_height: int) -> List[ImageInfo]:
    """å¢å¼ºç‰ˆå›¾ç‰‡æå–"""
    images = []
    img_counter = 1
    
    def process_shape(shape):
        nonlocal img_counter
        try:
            if shape.shape_type == MSO_SHAPE_TYPE.PICTURE:
                image = shape.image
                ext = image.ext.lstrip('.')
                
                # è·å–ä½ç½®å’Œå°ºå¯¸
                left = getattr(shape, 'left', 0)
                top = getattr(shape, 'top', 0)
                width = getattr(shape, 'width', 0)
                height = getattr(shape, 'height', 0)
                
                # è®¡ç®—å®½é«˜æ¯”
                aspect = width / height if height > 0 else 1.0
                
                # ç”Ÿæˆæ–‡ä»¶å
                img_filename = f"slide_{slide_num:02d}_img_{img_counter:02d}.{ext}"
                img_path = output_dir / img_filename
                
                # ä¿å­˜å›¾ç‰‡
                with open(img_path, 'wb') as f:
                    f.write(image.blob)
                
                # å°è¯•è·å–åŸå§‹æ–‡ä»¶å
                orig_name = getattr(image, 'filename', img_filename)
                
                info = ImageInfo(
                    filename=img_filename,
                    original_name=orig_name,
                    width_emu=width,
                    height_emu=height,
                    left_emu=left,
                    top_emu=top,
                    aspect_ratio=round(aspect, 2),
                    position_hint=get_image_position_hint(left, top, width, slide_width, slide_height),
                    size_hint=get_image_size_hint(width, height, slide_width, slide_height)
                )
                
                images.append(info)
                img_counter += 1
                
        except Exception:
            pass
    
    for shape in slide.shapes:
        process_shape(shape)
        # å¤„ç†ç»„åˆå½¢çŠ¶
        if shape.shape_type == MSO_SHAPE_TYPE.GROUP:
            for sub_shape in shape.shapes:
                process_shape(sub_shape)
    
    # æŒ‰ä½ç½®æ’åºï¼ˆä»å·¦åˆ°å³ï¼Œä»ä¸Šåˆ°ä¸‹ï¼‰
    images.sort(key=lambda x: (x.top_emu, x.left_emu))
    
    return images


def extract_text_enhanced(slide) -> Tuple[Optional[str], Optional[str], List[TextBlock]]:
    """
    å¢å¼ºç‰ˆæ–‡æœ¬æå–
    
    Returns:
        (æ ‡é¢˜, å‰¯æ ‡é¢˜, æ–‡æœ¬å—åˆ—è¡¨)
    """
    title = None
    subtitle = None
    text_blocks = []
    
    # ç”¨äºè¿½è¸ªå·²å¤„ç†çš„å ä½ç¬¦
    title_found = False
    subtitle_found = False
    
    for shape in slide.shapes:
        try:
            if not shape.has_text_frame:
                continue
            
            text_frame = shape.text_frame
            shape_type = "other"
            is_title_shape = False
            is_subtitle_shape = False
            
            # æ£€æŸ¥å ä½ç¬¦ç±»å‹
            if shape.is_placeholder:
                try:
                    ph_type = shape.placeholder_format.type
                    # TITLE=1, CENTER_TITLE=3, SUBTITLE=4, BODY=2
                    if ph_type in [1, 3]:
                        is_title_shape = True
                        shape_type = "title"
                    elif ph_type == 4:
                        is_subtitle_shape = True
                        shape_type = "subtitle"
                    elif ph_type == 2:
                        shape_type = "body"
                except:
                    pass
            
            # æå–æ®µè½
            for para_idx, para in enumerate(text_frame.paragraphs):
                # æ”¶é›†æ®µè½æ–‡æœ¬
                para_text = ""
                is_bold = False
                font_size = None
                
                for run in para.runs:
                    para_text += run.text
                    # è·å–æ ¼å¼ä¿¡æ¯
                    if run.font.bold:
                        is_bold = True
                    if run.font.size:
                        font_size = run.font.size.pt
                
                para_text = para_text.strip()
                if not para_text:
                    continue
                
                # è·å–ç¼©è¿›å±‚çº§
                level = para.level if para.level is not None else 0
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯åˆ—è¡¨é¡¹
                is_bullet = level > 0 or (hasattr(para, 'bullet') and para.bullet is not None)
                
                # å¤„ç†æ ‡é¢˜
                if is_title_shape and not title_found:
                    title = para_text
                    title_found = True
                    continue
                
                # å¤„ç†å‰¯æ ‡é¢˜
                if is_subtitle_shape and not subtitle_found:
                    subtitle = para_text
                    subtitle_found = True
                    continue
                
                # åˆ›å»ºæ–‡æœ¬å—
                block = TextBlock(
                    text=para_text,
                    level=level,
                    is_title=is_title_shape,
                    is_subtitle=is_subtitle_shape,
                    is_bullet=is_bullet,
                    font_size=font_size,
                    is_bold=is_bold,
                    shape_type=shape_type
                )
                text_blocks.append(block)
                
        except Exception:
            continue
    
    return title, subtitle, text_blocks


def extract_speaker_notes(slide) -> str:
    """æå–æ¼”è®²è€…å¤‡æ³¨"""
    try:
        if slide.has_notes_slide:
            notes_slide = slide.notes_slide
            notes_text_frame = notes_slide.notes_text_frame
            notes = []
            for para in notes_text_frame.paragraphs:
                para_text = "".join(run.text for run in para.runs).strip()
                if para_text:
                    notes.append(para_text)
            return "\n".join(notes)
    except Exception:
        pass
    return ""


def get_layout_name(slide) -> str:
    """è·å–å¹»ç¯ç‰‡å¸ƒå±€åç§°"""
    try:
        return slide.slide_layout.name
    except:
        return "Unknown"


# =============================================================================
# Markdown ç”Ÿæˆ
# =============================================================================

def generate_marp_header(title: str, total_slides: int, source_file: str) -> str:
    """ç”Ÿæˆå¢å¼ºçš„ Marp YAML å¤´éƒ¨"""
    timestamp = datetime.now().isoformat()
    return f"""---
marp: true
theme: default
paginate: true
size: 16:9
header: "{title}"
footer: "Course Refactoring Draft"
# === AI REFACTORING METADATA ===
# source_file: {source_file}
# total_slides: {total_slides}
# extracted_at: {timestamp}
# version: 2.0
---

"""


def generate_slide_markdown(slide_data: SlideData, asset_folder: str) -> str:
    """ç”Ÿæˆå•å¼ å¹»ç¯ç‰‡çš„ Markdown"""
    lines = []
    
    # === æ ‡é¢˜ ===
    # ä¼˜å…ˆä½¿ç”¨åŸå§‹æ ‡é¢˜ï¼Œç»ä¸ä½¿ç”¨é¡µç 
    if slide_data.title:
        lines.append(f"# {slide_data.title}")
    elif slide_data.subtitle:
        # å›é€€åˆ°å‰¯æ ‡é¢˜
        lines.append(f"# {slide_data.subtitle}")
    elif slide_data.text_blocks:
        # å°è¯•ä»ç¬¬ä¸€ä¸ªæ–‡æœ¬å—æ¨æ–­æ ‡é¢˜
        first_block = slide_data.text_blocks[0]
        if first_block.is_bold or (first_block.font_size and first_block.font_size > 20):
            lines.append(f"# {first_block.text}")
        else:
            # ä½¿ç”¨æè¿°æ€§å ä½ç¬¦ï¼Œæ–¹ä¾¿ AI åç»­å¤„ç†
            lines.append("# (Untitled - needs AI review)")
    elif slide_data.images:
        # çº¯å›¾ç‰‡é¡µ
        lines.append("# (Visual Content)")
    else:
        lines.append("# (Untitled - needs AI review)")
    
    lines.append("")
    
    # === å›¾ç‰‡ ===
    if slide_data.images:
        primary_img = slide_data.images[0]
        asset_path = f"assets/{asset_folder}/{primary_img.filename}"
        lines.append(primary_img.to_marp_directive(asset_path))
        lines.append("")
        
        # é¢å¤–å›¾ç‰‡è®°å½•åœ¨æ³¨é‡Šä¸­
        if len(slide_data.images) > 1:
            lines.append("<!-- [ADDITIONAL_IMAGES]")
            for img in slide_data.images[1:]:
                img_path = f"assets/{asset_folder}/{img.filename}"
                lines.append(f"  - {img_path} (position: {img.position_hint}, size: {img.size_hint})")
            lines.append("[END_IMAGES] -->")
            lines.append("")
    
    # === æ­£æ–‡å†…å®¹ ===
    content_added = False
    if slide_data.text_blocks:
        for block in slide_data.text_blocks:
            # è·³è¿‡å·²ç”¨ä½œæ ‡é¢˜çš„å†…å®¹
            if block.text == slide_data.title or block.text == slide_data.subtitle:
                continue
            
            # æ ¹æ®å±‚çº§ç”Ÿæˆç¼©è¿›
            indent = "  " * block.level
            prefix = "-"
            
            # æ¸…ç†æ–‡æœ¬
            clean_text = " ".join(block.text.split())
            if clean_text:
                lines.append(f"{indent}{prefix} {clean_text}")
                content_added = True
        
        if content_added:
            lines.append("")
    
    # === ç»“æ„åŒ–å…ƒæ•°æ®æ³¨é‡Šå— ===
    lines.append("<!--")
    lines.append(f"[SLIDE_META]")
    lines.append(f"  position: {slide_data.index}/{slide_data.total}")
    lines.append(f"  type: {slide_data.slide_type.value}")
    lines.append(f"  layout: {slide_data.layout_name}")
    lines.append(f"  density: {slide_data.content_density.value}")
    lines.append(f"  est_time_sec: {slide_data.estimated_speak_time_sec}")
    
    if slide_data.is_section_start:
        lines.append(f"  section_start: true")
        if slide_data.section_title:
            lines.append(f"  section_title: {slide_data.section_title}")
    
    if slide_data.continues_from_previous:
        lines.append(f"  continues_from_previous: true")
    if slide_data.continues_to_next:
        lines.append(f"  continues_to_next: true")
    
    if slide_data.key_terms:
        lines.append(f"  key_terms: {', '.join(slide_data.key_terms)}")
    
    lines.append(f"[END_META]")
    lines.append("")
    
    # === æ¼”è®²è€…å¤‡æ³¨ ===
    lines.append("[SPEAKER_NOTES]")
    if slide_data.speaker_notes:
        lines.append(slide_data.speaker_notes)
    else:
        lines.append("(No speaker notes)")
    lines.append("[END_NOTES]")
    lines.append("-->")
    
    return "\n".join(lines)


# =============================================================================
# ä¸»å¤„ç†å‡½æ•°
# =============================================================================

def process_single_pptx(pptx_path: Path, assets_base_dir: Path, 
                        verbose: bool = False) -> Tuple[bool, str, Dict[str, Any]]:
    """
    å¤„ç†å•ä¸ª PPTX æ–‡ä»¶
    
    Returns:
        (æˆåŠŸæ ‡å¿—, æ¶ˆæ¯, ç»Ÿè®¡ä¿¡æ¯)
    """
    stats = {
        "slides": 0,
        "images": 0,
        "notes_count": 0,
        "sections": 0,
        "warnings": []
    }
    
    try:
        stem = pptx_path.stem
        sanitized_stem = sanitize_filename(stem)
        
        # åˆ›å»ºèµ„æºç›®å½•
        asset_dir = assets_base_dir / sanitized_stem
        asset_dir.mkdir(parents=True, exist_ok=True)
        
        # è¾“å‡ºæ–‡ä»¶
        md_path = pptx_path.parent / f"{sanitized_stem}.md"
        
        # æ‰“å¼€ PPT
        prs = Presentation(str(pptx_path))
        total_slides = len(prs.slides)
        stats["slides"] = total_slides
        
        # è·å–å¹»ç¯ç‰‡å°ºå¯¸
        slide_width = prs.slide_width
        slide_height = prs.slide_height
        
        # === ç¬¬ä¸€éï¼šæå–æ‰€æœ‰æ•°æ® ===
        slides_data: List[SlideData] = []
        prev_title = None
        
        for slide_idx, slide in enumerate(prs.slides, start=1):
            # æå–å†…å®¹
            images = extract_images_enhanced(slide, slide_idx, asset_dir, slide_width, slide_height)
            title, subtitle, text_blocks = extract_text_enhanced(slide)
            notes = extract_speaker_notes(slide)
            layout_name = get_layout_name(slide)
            
            # ç»Ÿè®¡
            stats["images"] += len(images)
            if notes:
                stats["notes_count"] += 1
            
            # æ£€æµ‹ç« èŠ‚
            is_section, section_title = detect_section_start(title or "", layout_name, prev_title)
            if is_section:
                stats["sections"] += 1
            
            # æ£€æµ‹å»¶ç»­æ€§
            continues_from = is_continuation_title(title) if title else False
            
            # æ„å»ºå…¨æ–‡ç”¨äºåˆ†æ
            all_text = " ".join([title or "", subtitle or ""] + [tb.text for tb in text_blocks] + [notes])
            
            # åˆ›å»ºæ•°æ®å¯¹è±¡
            slide_data = SlideData(
                index=slide_idx,
                total=total_slides,
                title=title,
                subtitle=subtitle,
                text_blocks=text_blocks,
                images=images,
                speaker_notes=notes,
                slide_type=detect_slide_type(title, text_blocks, images, layout_name),
                content_density=assess_content_density(text_blocks, images),
                has_animation=False,  # python-pptx ä¸ç›´æ¥æ”¯æŒåŠ¨ç”»æ£€æµ‹
                layout_name=layout_name,
                is_section_start=is_section,
                section_title=section_title,
                estimated_speak_time_sec=estimate_speak_time(all_text, notes),
                key_terms=extract_key_terms(all_text),
                continues_from_previous=continues_from,
                continues_to_next=False  # åé¢å¤„ç†
            )
            
            slides_data.append(slide_data)
            prev_title = title
        
        # === ç¬¬äºŒéï¼šæ ‡è®°å»¶ç»­å…³ç³» ===
        for i in range(len(slides_data) - 1):
            if slides_data[i + 1].continues_from_previous:
                slides_data[i].continues_to_next = True
        
        # === ç”Ÿæˆ Markdown ===
        md_content = generate_marp_header(stem, total_slides, pptx_path.name)
        
        for i, sd in enumerate(slides_data):
            md_content += generate_slide_markdown(sd, sanitized_stem)
            
            # å¹»ç¯ç‰‡åˆ†éš”ç¬¦
            if i < len(slides_data) - 1:
                md_content += "\n\n---\n\n"
            else:
                md_content += "\n"
        
        # å†™å…¥æ–‡ä»¶
        with open(md_path, 'w', encoding='utf-8') as f:
            f.write(md_content)
        
        # === ç”Ÿæˆé…å¥—çš„ JSON å…ƒæ•°æ®ï¼ˆæ–¹ä¾¿ç¨‹åºåŒ–å¤„ç†ï¼‰===
        meta_path = pptx_path.parent / f"{sanitized_stem}_meta.json"
        meta = {
            "source": pptx_path.name,
            "output": md_path.name,
            "extracted_at": datetime.now().isoformat(),
            "stats": stats,
            "structure": {
                "total_slides": total_slides,
                "sections": [
                    {"index": sd.index, "title": sd.section_title}
                    for sd in slides_data if sd.is_section_start
                ]
            },
            "slides": [
                {
                    "index": sd.index,
                    "title": sd.title,
                    "subtitle": sd.subtitle,
                    "type": sd.slide_type.value,
                    "density": sd.content_density.value,
                    "layout": sd.layout_name,
                    "has_notes": bool(sd.speaker_notes),
                    "image_count": len(sd.images),
                    "text_block_count": len(sd.text_blocks),
                    "is_section_start": sd.is_section_start,
                    "section_title": sd.section_title,
                    "key_terms": sd.key_terms,
                    "est_time_sec": sd.estimated_speak_time_sec,
                    "continues_from_previous": sd.continues_from_previous,
                    "continues_to_next": sd.continues_to_next
                }
                for sd in slides_data
            ]
        }
        with open(meta_path, 'w', encoding='utf-8') as f:
            json.dump(meta, f, ensure_ascii=False, indent=2)
        
        msg = f"âœ“ {total_slides} slides, {stats['images']} imgs, {stats['notes_count']} notes, {stats['sections']} sections"
        return True, msg, stats
        
    except Exception as e:
        stats["warnings"].append(str(e))
        return False, f"âœ— Error: {str(e)}", stats


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(
        description="æ‰¹é‡å°† PPTX è½¬æ¢ä¸º AI å‹å¥½çš„ Marp Markdown"
    )
    parser.add_argument("--verbose", "-v", action="store_true", help="æ˜¾ç¤ºè¯¦ç»†è¾“å‡º")
    parser.add_argument("--output-dir", "-o", type=str, help="æŒ‡å®šè¾“å‡ºç›®å½•ï¼ˆé»˜è®¤ä¸ºå½“å‰ç›®å½•ï¼‰")
    args = parser.parse_args()
    
    print()
    print("â•”" + "â•" * 58 + "â•—")
    print("â•‘" + "  PPTX â†’ Marp Converter v2.0".center(58) + "â•‘")
    print("â•‘" + "  Optimized for AI-Assisted Refactoring".center(58) + "â•‘")
    print("â•š" + "â•" * 58 + "â•")
    print()
    
    # ç¡®å®šå·¥ä½œç›®å½•
    current_dir = Path(args.output_dir) if args.output_dir else Path.cwd()
    print(f"ğŸ“ Working Directory: {current_dir}")
    print()
    
    # æ‰«æ PPTX æ–‡ä»¶
    pptx_files = sorted(current_dir.glob("*.pptx"))
    
    # æ’é™¤ä¸´æ—¶æ–‡ä»¶
    pptx_files = [f for f in pptx_files if not f.name.startswith("~$")]
    
    if not pptx_files:
        print("âš ï¸  No .pptx files found in current directory.")
        print("   Please run this script in the folder containing your PPT files.")
        sys.exit(0)
    
    print(f"ğŸ“Š Found {len(pptx_files)} PPTX file(s):")
    for f in pptx_files:
        print(f"   â€¢ {f.name}")
    print()
    
    # åˆ›å»º assets ç›®å½•
    assets_dir = current_dir / "assets"
    assets_dir.mkdir(exist_ok=True)
    
    # å¤„ç†ç»Ÿè®¡
    results = {
        "success": 0,
        "failed": 0,
        "total_slides": 0,
        "total_images": 0,
        "total_notes": 0
    }
    
    print("â”€" * 60)
    print("Processing...")
    print("â”€" * 60)
    
    for idx, pptx_file in enumerate(pptx_files, start=1):
        prefix = f"[{idx:2d}/{len(pptx_files)}]"
        print(f"{prefix} {pptx_file.name}")
        
        success, message, stats = process_single_pptx(pptx_file, assets_dir, args.verbose)
        
        print(f"       {message}")
        
        if success:
            results["success"] += 1
            results["total_slides"] += stats["slides"]
            results["total_images"] += stats["images"]
            results["total_notes"] += stats["notes_count"]
        else:
            results["failed"] += 1
        
        if args.verbose and stats.get("warnings"):
            for warn in stats["warnings"]:
                print(f"       âš ï¸  {warn}")
    
    # æœ€ç»ˆæŠ¥å‘Š
    print()
    print("â”€" * 60)
    print("ğŸ“ˆ Summary")
    print("â”€" * 60)
    print(f"   Files processed:  {len(pptx_files)}")
    print(f"   Successful:       {results['success']}")
    print(f"   Failed:           {results['failed']}")
    print()
    print(f"   Total slides:     {results['total_slides']}")
    print(f"   Total images:     {results['total_images']}")
    print(f"   Slides w/ notes:  {results['total_notes']}")
    print()
    print("ğŸ“‚ Output Structure:")
    print(f"   Markdown:  {current_dir}/*.md")
    print(f"   Metadata:  {current_dir}/*_meta.json")
    print(f"   Images:    {assets_dir}/<filename>/")
    print()
    print("ğŸš€ Ready for multi-stage AI refactoring!")
    print()


if __name__ == "__main__":
    main()
